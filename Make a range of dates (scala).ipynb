{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a range of dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://HQSWL-1650935.cable.comcast.com:4044\n",
       "SparkContext available as 'sc' (version = 2.4.0, master = local[*], app id = local-1562807324616)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-10 21:08:41 ERROR Shell:397 - Failed to locate the winutils binary in the hadoop binary path\r\n",
      "java.io.IOException: Could not locate executable null\\bin\\winutils.exe in the Hadoop binaries.\r\n",
      "\tat org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:379)\r\n",
      "\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:394)\r\n",
      "\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:387)\r\n",
      "\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)\r\n",
      "\tat org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)\r\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:273)\r\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:261)\r\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:791)\r\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:761)\r\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:634)\r\n",
      "\tat org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2422)\r\n",
      "\tat org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2422)\r\n",
      "\tat scala.Option.getOrElse(Option.scala:121)\r\n",
      "\tat org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2422)\r\n",
      "\tat org.apache.spark.SecurityManager.<init>(SecurityManager.scala:79)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.secMgr$lzycompute$1(SparkSubmit.scala:359)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$secMgr$1(SparkSubmit.scala:359)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7.apply(SparkSubmit.scala:367)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anonfun$prepareSubmitEnvironment$7.apply(SparkSubmit.scala:367)\r\n",
      "\tat scala.Option.map(Option.scala:146)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:366)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:143)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:86)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:924)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:933)\r\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\n",
      "2019-07-10 21:08:41 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\r\n",
      "2019-07-10 21:08:44 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\r\n",
      "2019-07-10 21:08:44 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\r\n",
      "2019-07-10 21:08:44 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\r\n",
      "2019-07-10 21:08:44 WARN  Utils:66 - Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.joda.time._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.joda.time._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-02\n",
      "2019-03-03\n",
      "2019-03-04\n",
      "2019-03-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "makeDates: (start_date: String, end_date: String)scala.collection.immutable.IndexedSeq[String]\r\n",
       "start_date: String = 2019-03-02\r\n",
       "end_date: String = 2019-03-05\r\n",
       "exclude_dates: Array[String] = Array(\"\")\r\n",
       "dates: scala.collection.immutable.IndexedSeq[String] = Vector(2019-03-02, 2019-03-03, 2019-03-04, 2019-03-05)\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def makeDates(start_date: String, end_date: String) = {\n",
    "  val start = new org.joda.time.LocalDate(start_date)\n",
    "  val end = new org.joda.time.LocalDate(end_date)\n",
    "  val days = Days.daysBetween(start, end).getDays()\n",
    "  for(d <- 0 to days) yield start.plusDays(d).toString(\"yyyy-MM-dd\")\n",
    "}\n",
    "\n",
    "val start_date = \"2019-03-02\"\n",
    "val end_date = \"2019-03-05\"\n",
    "val exclude_dates = Array(\"\")\n",
    "\n",
    "val dates = makeDates(start_date, end_date).filterNot(exclude_dates.contains(_))\n",
    "\n",
    "for (d <- dates){\n",
    "val day  = new LocalDate(d)\n",
    "  println (day)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
