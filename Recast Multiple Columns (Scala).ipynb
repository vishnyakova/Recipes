{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "|time| color|count|\n",
      "+----+------+-----+\n",
      "| 1.1|orange|    1|\n",
      "| 3.2|   red|    1|\n",
      "| 2.1|   red|    1|\n",
      "| 1.5|   red|    1|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cols_time: Seq[String] = List(time)\r\n",
       "cols_count: Seq[String] = List(count)\r\n",
       "df: org.apache.spark.sql.DataFrame = [time: string, color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cols_time = Seq(\"time\")\n",
    "val cols_count = Seq(\"count\")\n",
    "\n",
    "val df = Seq(\n",
    "  (\"1.1\",  \"orange\", \"1\"),\n",
    "  (\"3.2\",  \"red\", \"1\"),\n",
    "  (\"2.1\",  \"red\", \"1\"), \n",
    "  (\"1.5\",  \"red\", \"1\")\n",
    ")\n",
    ".toDF(\"time\", \"color\", \"count\")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|time|color|count|\n",
      "+----+-----+-----+\n",
      "|   1| null|    1|\n",
      "|   3| null|    1|\n",
      "|   2| null|    1|\n",
      "|   1| null|    1|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newDF: org.apache.spark.sql.DataFrame = [time: int, color: int ... 1 more field]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cast all columns\n",
    "val newDF = df.select(df.columns.map(c => df.col(c).cast(\"integer\")): _*)\n",
    "\n",
    "newDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "|time| color|count|\n",
      "+----+------+-----+\n",
      "|   1|orange|    1|\n",
      "|   3|   red|    1|\n",
      "|   2|   red|    1|\n",
      "|   1|   red|    1|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newDF: org.apache.spark.sql.DataFrame = [time: int, color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cast columns based on condition\n",
    "val newDF = df\n",
    ".select(\n",
    "  df.columns map (  c => if(cols_time.contains(c)) col(c).cast(\"integer\") else col(c)): _*\n",
    ")\n",
    "\n",
    "newDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+-----+\n",
      "|time| color|count|\n",
      "+----+------+-----+\n",
      "| 1.1|orange|    1|\n",
      "| 3.2|   red|    1|\n",
      "| 2.1|   red|    1|\n",
      "| 1.5|   red|    1|\n",
      "+----+------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newDF: org.apache.spark.sql.DataFrame = [time: string, color: string ... 1 more field]\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// cast columns with more conditions\n",
    "val newDF = df\n",
    ".select(\n",
    "  df.columns map (  c => if(cols_latency.contains(c)) \n",
    "                  {col(c).cast(\"float\")}\n",
    "                  else if(cols_count.contains(c))\n",
    "                  {col(c)}\n",
    "                  else col(c)\n",
    "                 ): _*)\n",
    "\n",
    "newDF.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
